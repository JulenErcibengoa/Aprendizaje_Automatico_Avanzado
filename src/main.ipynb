{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Aprendizaje Automático Avanzado: Ejercicio final</center>\n",
    "### <center>Autor: Julen Ercibengoa</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Contexto\n",
    "\n",
    "Actualmente estoy trabajando en la empresa **Tekniker** la cual está involucrada en el proyecto GAIA. Este es un proyecto que pretende dar apoyo a los servicios de extinción de incendios forestales mediante herramientas de prevención y detección temprana utilizando la Inteligencia Artificial.\n",
    "\n",
    "Mi trabajo consiste en crear un modelo de Aprendizaje Automático que prediga el riesgo de incendio forestal a nivel nacional diariamente. Es decir, el objetivo final del trabajo (el cual es mi Trabajo de Fin de Máster), es generar un modelo que con los datos disponibles hasta hoy, genere un mapa de mañana de riesgo de incendio forestal en toda España. \n",
    "\n",
    "Para conseguir ese objetivo hacen falta varios pasos, y este trabajo será uno de ellos. En este trabajo haremos una primera prueba y generaremos un predictor de riesgo de incendio forestal que prediga el riesgo de incendio forestal mensual. Además, haremos varios análisis para decidir qué variable son relevantes para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bases de Datos\n",
    "\n",
    "Para predecir el riesgo de incendio forestal hay que generar una base de datos con la cual entrenar un modelo de Inteligencia Artificial. En el estado del arte [(Ver el análisis del estado del arte)](SOTA.pdf) se sigue una metodología común que vamos a utilizar: se divide la región a analizar en celdas espacio-temporales y cada celda tiene asignadas variables tabulares. Para generar dicha base de datos, vamos a utilizar las siguientes fuentes de datos:\n",
    "- <u>Datos históricos de fuegos</u>: base de datos de [EFFIS](https://forest-fire.emergency.copernicus.eu/)\n",
    "- <u>Datos del tipo de terreno</u>: base de datos [Corine Land Cover](https://land.copernicus.eu/en/products/corine-land-cover)\n",
    "- <u>Datos DEM (Digital Elevation Model)</u>: base de datos de [EU DEM](https://portal.opentopography.org/raster?opentopoID=OTSDEM.032021.4326.3&minX=-17.18261718749999&minY=31.097629956393973&maxX=15.952148437499998&maxY=45.43508099838451)\n",
    "- <u>Distancia a carreteras</u>, <u>distancia a rios</u> y <u>densidad poblacional</u>: [WorldPop](https://www.worldpop.org/)\n",
    "- <u>Distancia a vías de tren</u>: [OpenStreetMap](https://www.openstreetmap.org/#map=6/40.01/-2.49)\n",
    "- <u>Proporción de natura2000</u>: [Gobierno de España](https://www.miteco.gob.es/es/biodiversidad/servicios/banco-datos-naturaleza/informacion-disponible/rednatura_2000_desc.html)\n",
    "\n",
    "Aunque en las visualizaciones de los datos que vamos a hacer a continuación no aparezca, el área que vamos a analizar sera toda España, incluyendo las Islas Canarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Datos históricos de fuegos: EFFIS\n",
    "\n",
    "El primer conjunto de datos que vamos a utilizar serán los datos históricos de EFFIS (European Forest Fire Information System). Este conjunto de datos guarda la información de cuándo inició el fuego, cuándo finalizó, el área que quemó y la forma que tiene junto a dónde pasó. Los datos que tienen recogidos van desde 2008 hasta la actualidad y usaremos solo los incendios de más de 5 hectáreas, con un total de 5862 fuegos.\n",
    "\n",
    "Para visualizar el conjunto de datos utilizaremos el paquete **geopandas**, que permite visualizar los datos con información geográfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialdate</th>\n",
       "      <th>finaldate</th>\n",
       "      <th>area_ha</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-04-27</td>\n",
       "      <td>2008-04-27</td>\n",
       "      <td>419</td>\n",
       "      <td>MULTIPOLYGON (((1652130.767 1048788.051, 16513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-06-17</td>\n",
       "      <td>2008-06-17</td>\n",
       "      <td>104</td>\n",
       "      <td>MULTIPOLYGON (((3252074.625 1640344.173, 32521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-06-19</td>\n",
       "      <td>2008-06-19</td>\n",
       "      <td>523</td>\n",
       "      <td>MULTIPOLYGON (((2906844.761 1591397.039, 29068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>2008-07-01</td>\n",
       "      <td>253</td>\n",
       "      <td>MULTIPOLYGON (((3016594.759 1855823.362, 30161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>58</td>\n",
       "      <td>MULTIPOLYGON (((3115823.664 1790836.728, 31160...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  initialdate  finaldate  area_ha  \\\n",
       "0  2008-04-27 2008-04-27      419   \n",
       "1  2008-06-17 2008-06-17      104   \n",
       "2  2008-06-19 2008-06-19      523   \n",
       "3  2008-07-01 2008-07-01      253   \n",
       "4  2008-07-07 2008-07-07       58   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((1652130.767 1048788.051, 16513...  \n",
       "1  MULTIPOLYGON (((3252074.625 1640344.173, 32521...  \n",
       "2  MULTIPOLYGON (((2906844.761 1591397.039, 29068...  \n",
       "3  MULTIPOLYGON (((3016594.759 1855823.362, 30161...  \n",
       "4  MULTIPOLYGON (((3115823.664 1790836.728, 31160...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "gdf_fires = gpd.read_file(\"../data/Variables/EFFIS_historical_postprocessed.json\")\n",
    "gdf_fires.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "gdf_fires = gdf_fires.to_crs(epsg=3857)\n",
    "minx, miny, maxx, maxy = gdf_fires.total_bounds\n",
    "ax = gdf_fires.plot(column=\"area_ha\", legend=True, figsize=(12,12), cmap=\"plasma\", legend_kwds={'label': \"Área quemada (ha)\", 'orientation': \"horizontal\", 'shrink': 0.5, 'aspect': 50, 'pad': 0.01})\n",
    "ax.set_xlim([-1.25*10**6, maxx])\n",
    "ax.set_ylim([4.25*10**6, maxy])\n",
    "ctx.add_basemap(ax, crs=gdf_fires.crs.to_string())\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Área quemada en España (2008-2024)\", fontsize=20, pad=20)\n",
    "plt.savefig(\"../data/figures/fires_plot.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../data/figures/fires_plot.png\" alt=\"Área quemada en España (2008-2024)\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Datos del tipo de terreno: Corine Land Cover\n",
    "\n",
    "El conjunto de datos Corine Land Cover divide a toda Europa en celdas de 100m $\\times$ 100m y asigna a cada celda una clase de las 44 clases que tienen definidas. Las clases son las siguientes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Class} & \\textbf{LABEL1} & \\textbf{LABEL2} & \\textbf{LABEL3} \\\\\n",
    "\\hline\n",
    "1 & \\text{Artificial surfaces} & \\text{Urban fabric} & \\text{Continuous urban fabric} \\\\\n",
    "\\hline\n",
    "2 & \\text{Artificial surfaces} & \\text{Urban fabric} & \\text{Discontinuous urban fabric} \\\\\n",
    "\\hline\n",
    "3 & \\text{Artificial surfaces} & \\text{Industrial, commercial and transport units} & \\text{Industrial or commercial units} \\\\\n",
    "\\hline\n",
    "4 & \\text{Artificial surfaces} & \\text{Industrial, commercial and transport units} & \\text{Road and rail networks and associated land} \\\\\n",
    "\\hline\n",
    "5 & \\text{Artificial surfaces} & \\text{Industrial, commercial and transport units} & \\text{Port areas} \\\\\n",
    "\\hline\n",
    "6 & \\text{Artificial surfaces} & \\text{Industrial, commercial and transport units} & \\text{Airports} \\\\\n",
    "\\hline\n",
    "7 & \\text{Artificial surfaces} & \\text{Mine, dump and construction sites} & \\text{Mineral extraction sites} \\\\\n",
    "\\hline\n",
    "8 & \\text{Artificial surfaces} & \\text{Mine, dump and construction sites} & \\text{Dump sites} \\\\\n",
    "\\hline\n",
    "9 & \\text{Artificial surfaces} & \\text{Mine, dump and construction sites} & \\text{Construction sites} \\\\\n",
    "\\hline\n",
    "10 & \\text{Artificial surfaces} & \\text{Artificial, non-agricultural vegetated areas} & \\text{Green urban areas} \\\\\n",
    "\\hline\n",
    "11 & \\text{Artificial surfaces} & \\text{Artificial, non-agricultural vegetated areas} & \\text{Sport and leisure facilities} \\\\\n",
    "\\hline\n",
    "12 & \\text{Agricultural areas} & \\text{Arable land} & \\text{Non-irrigated arable land} \\\\\n",
    "\\hline\n",
    "13 & \\text{Agricultural areas} & \\text{Arable land} & \\text{Permanently irrigated land} \\\\\n",
    "\\hline\n",
    "14 & \\text{Agricultural areas} & \\text{Arable land} & \\text{Rice fields} \\\\\n",
    "\\hline\n",
    "15 & \\text{Agricultural areas} & \\text{Permanent crops} & \\text{Vineyards} \\\\\n",
    "\\hline\n",
    "16 & \\text{Agricultural areas} & \\text{Permanent crops} & \\text{Fruit trees and berry plantations} \\\\\n",
    "\\hline\n",
    "17 & \\text{Agricultural areas} & \\text{Permanent crops} & \\text{Olive groves} \\\\\n",
    "\\hline\n",
    "18 & \\text{Agricultural areas} & \\text{Pastures} & \\text{Pastures} \\\\\n",
    "\\hline\n",
    "19 & \\text{Agricultural areas} & \\text{Heterogeneous agricultural areas} & \\text{Annual crops associated with permanent crops} \\\\\n",
    "\\hline\n",
    "20 & \\text{Agricultural areas} & \\text{Heterogeneous agricultural areas} & \\text{Complex cultivation patterns} \\\\\n",
    "\\hline\n",
    "21 & \\text{Agricultural areas} & \\text{Heterogeneous agricultural areas} & \\text{Land principally occupied by agriculture, with significant areas of natural vegetation} \\\\\n",
    "\\hline\n",
    "22 & \\text{Agricultural areas} & \\text{Heterogeneous agricultural areas} & \\text{Agro-forestry areas} \\\\\n",
    "\\hline\n",
    "23 & \\text{Forest and semi natural areas} & \\text{Forests} & \\text{Broad-leaved forest} \\\\\n",
    "\\hline\n",
    "24 & \\text{Forest and semi natural areas} & \\text{Forests} & \\text{Coniferous forest} \\\\\n",
    "\\hline\n",
    "25 & \\text{Forest and semi natural areas} & \\text{Forests} & \\text{Mixed forest} \\\\\n",
    "\\hline\n",
    "26 & \\text{Forest and semi natural areas} & \\text{Scrub and/or herbaceous vegetation associations} & \\text{Natural grasslands} \\\\\n",
    "\\hline\n",
    "27 & \\text{Forest and semi natural areas} & \\text{Scrub and/or herbaceous vegetation associations} & \\text{Moors and heathland} \\\\\n",
    "\\hline\n",
    "28 & \\text{Forest and semi natural areas} & \\text{Scrub and/or herbaceous vegetation associations} & \\text{Sclerophyllous vegetation} \\\\\n",
    "\\hline\n",
    "29 & \\text{Forest and semi natural areas} & \\text{Scrub and/or herbaceous vegetation associations} & \\text{Transitional woodland-shrub} \\\\\n",
    "\\hline\n",
    "30 & \\text{Forest and semi natural areas} & \\text{Open spaces with little or no vegetation} & \\text{Beaches, dunes, sands} \\\\\n",
    "\\hline\n",
    "31 & \\text{Forest and semi natural areas} & \\text{Open spaces with little or no vegetation} & \\text{Bare rocks} \\\\\n",
    "\\hline\n",
    "32 & \\text{Forest and semi natural areas} & \\text{Open spaces with little or no vegetation} & \\text{Sparsely vegetated areas} \\\\\n",
    "\\hline\n",
    "33 & \\text{Forest and semi natural areas} & \\text{Open spaces with little or no vegetation} & \\text{Burnt areas} \\\\\n",
    "\\hline\n",
    "34 & \\text{Forest and semi natural areas} & \\text{Open spaces with little or no vegetation} & \\text{Glaciers and perpetual snow} \\\\\n",
    "\\hline\n",
    "35 & \\text{Wetlands} & \\text{Inland wetlands} & \\text{Inland marshes} \\\\\n",
    "\\hline\n",
    "36 & \\text{Wetlands} & \\text{Inland wetlands} & \\text{Peat bogs} \\\\\n",
    "\\hline\n",
    "37 & \\text{Wetlands} & \\text{Maritime wetlands} & \\text{Salt marshes} \\\\\n",
    "\\hline\n",
    "38 & \\text{Wetlands} & \\text{Maritime wetlands} & \\text{Salines} \\\\\n",
    "\\hline\n",
    "39 & \\text{Wetlands} & \\text{Maritime wetlands} & \\text{Intertidal flats} \\\\\n",
    "\\hline\n",
    "40 & \\text{Water bodies} & \\text{Inland waters} & \\text{Water courses} \\\\\n",
    "\\hline\n",
    "41 & \\text{Water bodies} & \\text{Inland waters} & \\text{Water bodies} \\\\\n",
    "\\hline\n",
    "42 & \\text{Water bodies} & \\text{Marine waters} & \\text{Coastal lagoons} \\\\\n",
    "\\hline\n",
    "43 & \\text{Water bodies} & \\text{Marine waters} & \\text{Estuaries} \\\\\n",
    "\\hline\n",
    "44 & \\text{Water bodies} & \\text{Marine waters} & \\text{Sea and ocean} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos se actualiza cada 6 años, por lo que en nuestro caso utilizaremos los datos de 2006, 2012 y 2018. El siguiente gráfico es una visualización de los datos de 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "ruta_tiff = \"../data/Variables/U2018_CLC2018_V2020_20u1.tif\"\n",
    "custom_colors = pickle.load(open(\"../data/figures/custom_colors.pkl\", \"rb\"))\n",
    "\n",
    "with rasterio.open(ruta_tiff) as dataset:\n",
    "    datos = dataset.read(1)  \n",
    "datos = datos[:10000, 10000:]\n",
    "rgb_image = np.zeros((datos.shape[0], datos.shape[1], 3), dtype=np.uint8)\n",
    "for key, color in custom_colors.items():\n",
    "    rgb_image[datos == key] = color\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(rgb_image)\n",
    "plt.axis('off') \n",
    "plt.title(\"Corine Land Cover año 2018\", fontsize=18, pad = 20)\n",
    "legend_patches = [mpatches.Patch(color=np.array(color)/255, label=str(key)) for key, color in custom_colors.items()]\n",
    "legend_patches.pop(-1)\n",
    "plt.legend(handles=legend_patches,\n",
    "            loc='upper left',\n",
    "            title=\"Clases\", \n",
    "            fontsize=7)\n",
    "plt.savefig(\"../data/figures/CLC_plot.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../data/figures/CLC_plot.png\" alt=\"Área quemada en España (2008-2024)\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Datos DEM\n",
    "\n",
    "En cuanto a los datos DEM (Digital Elevation Model), usaremos tres fuentes de datos: la elevación del terreno (metros), la orientación del terreno (grados) y la pendiente (grados). Los datos los obtuvieron la \"European Space Agency\" y Copernicus, a una resolución de 30m $\\times$ 30m. En la siguiente imagen se pueden observar estas tres fuentes de datos graficados en Donostia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "dem_file = \"../data/Variables/DEM_donostia.tif\"\n",
    "aspect_file = \"../data/Variables/Aspect_donostia.tif\"\n",
    "slope_file = \"../data/Variables/Slope_donostia.tif\"\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "# Open the DEM file using rasterio\n",
    "with rasterio.open(dem_file) as src:\n",
    "    dem_data = src.read(1)  # Read the first band\n",
    "    dem_extent = (src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top)\n",
    "    im0 = ax[0].imshow(dem_data, cmap='terrain', extent=dem_extent)\n",
    "    ax[0].set_title(\"Modelo Digital de Elevación (DEM)\")\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    ax[0].set_ylim(src.bounds.bottom + 0.003, src.bounds.top)\n",
    "    # Add colorbar for the DEM\n",
    "    cbar0 = fig.colorbar(im0, ax=ax[0], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "    cbar0.set_label(\"Elevation (meters)\")\n",
    "\n",
    "with rasterio.open(aspect_file) as src:\n",
    "    im1 = show(src, ax=ax[1], title=\"Orientación\")\n",
    "    ax[1].set_ylim(src.bounds.bottom + 0.003, src.bounds.top)\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    # Add colorbar for the Aspect\n",
    "    norm = mcolors.Normalize(vmin=src.read(1).min(), vmax=src.read(1).max())\n",
    "    cbar1 = fig.colorbar(im1.get_images()[0], ax=ax[1], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "    cbar1.set_label(\"Orientación (grados)\")\n",
    "\n",
    "with rasterio.open(slope_file) as src:\n",
    "    im2 = show(src, ax=ax[2], title=\"Pendiente\")\n",
    "    ax[2].set_ylim(src.bounds.bottom + 0.003, src.bounds.top)\n",
    "    ax[2].set_xticks([])\n",
    "    ax[2].set_yticks([])\n",
    "    # Add colorbar for the Slope\n",
    "    norm = mcolors.Normalize(vmin=src.read(1).min(), vmax=src.read(1).max())\n",
    "    cbar2 = fig.colorbar(im2.get_images()[0], ax=ax[2], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "    cbar2.set_label(\"Pendiente (grados)\")\n",
    "\n",
    "plt.savefig(\"../data/figures/DEM_plots.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../data/figures/DEM_plots.png\" alt=\"Área quemada en España (2008-2024)\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Distancia a carreteras, distancia a rios, distancia a vías de tren y densidad poblacional\n",
    "\n",
    "Para introducir el factor humano usaremos estas cuatro variables, algunas creadas mediante el software QGIS:\n",
    "- Distancia a carreteras\n",
    "- Distancia a rios\n",
    "- Distancia a vías de tren\n",
    "- Densidad poblacional\n",
    "\n",
    "Esta última cambia con el tiempo y la base de datos de [WorldPop](https://www.worldpop.org/) ofrece datos anuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "railways_file = \"../data/Variables/Dist_to_railways_SPAIN.tif\"\n",
    "roads_file = \"../data/Variables/Dist_to_roads_SPAIN.tif\"\n",
    "waterways_file = \"../data/Variables/Dist_to_waterways_SPAIN.tif\"\n",
    "popdens_file = \"../data/Variables/Pop_dens_SPAIN.tif\"\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(25, 20))\n",
    "\n",
    "# Open the DEM file using rasterio\n",
    "with rasterio.open(popdens_file) as src:\n",
    "    im1 = show(src, ax=ax[0,0], title=\"Densidad poblacional (2020)\")\n",
    "    ax[0,0].set_ylim(src.bounds.bottom + 0.05, src.bounds.top-0.05)\n",
    "    ax[0,0].set_xlim(src.bounds.left + 0.05, src.bounds.right-0.05)\n",
    "    ax[0,0].set_xticks([])\n",
    "    ax[0,0].set_yticks([])\n",
    "    ax[0,0].set_title(\"Densidad poblacional (2020)\", fontsize=25)\n",
    "    norm = mcolors.Normalize(vmin=src.read(1).min(), vmax=src.read(1).max())\n",
    "    cbar1 = fig.colorbar(im1.get_images()[0], ax=ax[0,0], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "\n",
    "with rasterio.open(roads_file) as src:\n",
    "    im1 = show(src, ax=ax[1,0], title=\"Distancia a carreteras\")\n",
    "    ax[1,0].set_ylim(src.bounds.bottom + 0.05, src.bounds.top-0.05)\n",
    "    ax[1,0].set_xlim(src.bounds.left + 0.05, src.bounds.right-0.05)\n",
    "    ax[1,0].set_xticks([])\n",
    "    ax[1,0].set_yticks([])\n",
    "    ax[1,0].set_title(\"Distancia a carreteras\", fontsize=25)\n",
    "    norm = mcolors.Normalize(vmin=src.read(1).min(), vmax=src.read(1).max())\n",
    "    cbar1 = fig.colorbar(im1.get_images()[0], ax=ax[1,0], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "\n",
    "with rasterio.open(waterways_file) as src:\n",
    "    im2 = show(src, ax=ax[0,1], title=\"Distancia a rios\")\n",
    "    ax[0,1].set_ylim(src.bounds.bottom + 0.05, src.bounds.top-0.05)\n",
    "    ax[0,1].set_xlim(src.bounds.left + 0.05, src.bounds.right-0.05)\n",
    "    ax[0,1].set_xticks([])\n",
    "    ax[0,1].set_yticks([])\n",
    "    ax[0,1].set_title(\"Distancia a rios\", fontsize=25)\n",
    "    norm = mcolors.Normalize(vmin=src.read(1).min(), vmax=src.read(1).max())\n",
    "    cbar2 = fig.colorbar(im2.get_images()[0], ax=ax[0,1], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "\n",
    "with rasterio.open(railways_file) as src:\n",
    "    im2 = show(src, ax=ax[1,1], title=\"Distancia a vias de tren\")\n",
    "    ax[1,1].set_ylim(src.bounds.bottom + 0.05, src.bounds.top-0.05)\n",
    "    ax[1,1].set_xlim(src.bounds.left + 0.05, src.bounds.right-0.05)\n",
    "    ax[1,1].set_xticks([])\n",
    "    ax[1,1].set_yticks([])\n",
    "    norm = mcolors.Normalize(vmin=src.read(1).min(), vmax=src.read(1).max())\n",
    "    cbar2 = fig.colorbar(im2.get_images()[0], ax=ax[1,1], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "    ax[1,1].set_title(\"Distancia a vias de tren\", fontsize=25)\n",
    "\n",
    "plt.savefig(\"../data/figures/Humans_plot.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../data/figures/Humans_plot.png\" alt=\"Área quemada en España (2008-2024)\" width=\"1300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Natura2000\n",
    "\n",
    "La red Natura 2000 es una red ecológica europea de áreas de conservación de la biodiversidad. Introduciremos esta variable porque el conjunto de datos de EFFIS original también la utiliza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "\n",
    "Natura2000 = gpd.read_file(\"../data/Variables/N2000_2.geojson\")\n",
    "ax = Natura2000.plot(figsize=(10, 10), alpha=0.5, edgecolor='k', color='lightgreen')\n",
    "ax.set_title(\"Red Natura 2000 en España\", fontsize=20)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ctx.add_basemap(ax, crs=Natura2000.crs.to_string())\n",
    "\n",
    "plt.savefig(\"../data/figures/Natura2000.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../data/figures/Natura2000.png\" alt=\"Área quemada en España (2008-2024)\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Homogeneización de los datos\n",
    "En esta sección vamos a explicar brevemente cómo se han homogeneizado los datos. \n",
    "\n",
    "### 3.1 Instancias del dataset\n",
    "\n",
    "Para transformar las bases de datos que hemos presentado en un dataset con datos tabulares, vamos a utilizar celdas espacio-temporales, las cuales serán nuestras instancias que utilizaremos para entrenar los algoritmos. Para ello, hemos creado celdas espaciales que cubren toda España con una resolución espacial de 1km $\\times$ 1km. También hemos creado celdas con resolución espacial de 20km $\\times$ 20km para visualizarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_visual_20 = gpd.read_file(\"../data/Variables/Spain_boxes_20km.json\")\n",
    "boxes_visual_1 = gpd.read_file(\"../data/Variables/Spain_boxes_1km.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "boxes_visual_20.plot(ax=ax[0], edgecolor='k', color='lightblue')\n",
    "ax[0].set_title(\"Celdas de 20km x 20km (para visualizar)\", fontsize=20)\n",
    "ax[0].set_xlim([2.5*10**6, 3.9*10**6])\n",
    "ax[0].set_ylim([1.5*10**6, 2.5*10**6])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "\n",
    "boxes_visual_1.plot(ax= ax[1], edgecolor='k', color='red', figsize=(10, 10), alpha=0.1)\n",
    "ax[1].set_title(\"Celdas de 1km x 1km\", fontsize=20)\n",
    "ax[1].set_xlim([3.345*10**6, 3.37*10**6])\n",
    "ax[1].set_ylim([2.31*10**6, 2.33*10**6])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ctx.add_basemap(ax[1], crs=boxes_visual_1.crs.to_string())\n",
    "\n",
    "plt.savefig(\"../data/figures/Boxes.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../data/figures/Boxes.png\" alt=\"Área quemada en España (2008-2024)\" width=\"1500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables tabulares:\n",
    "\n",
    "Cada celda de 1km $\\times$ 1km tendrá asignadas varias variables tabulares:\n",
    "- <u>Corine Land Cover</u>: para cada clase, generaremos una variable que será la proporción de casillas de 100m $\\times$ 100m de esa clase que hay en la celda. Por lo que el dataset CLC nos dará 44 variables.\n",
    "- <u>DEM</u>: \n",
    "    - <u>Elevación</u>: Para cada celda espacial, calcularemos las siguientes variables de elevación: suma, media , mediana, desviación estandar, mínimo, máximo y rango.\n",
    "    - <u>Orientación</u>: Dividiremos 360º en 8 clases: (0-45), (45-90), (90-135), (135-180), (180-225), (225-270), (270-315), y (315-360). Para cada clase de orientación, se calculará la proporción de celdas de 30m × 30m que pertenecen a esa clase dentro de la celda de 1km × 1km. Esto nos dará 8 variables adicionales asociadas a la orientación.\n",
    "    - <u>Pendiente</u>: Para cada celda espacial, calcularemos las siguientes variables de pendiente: suma, media , mediana, desviación estandar, mínimo, máximo y rango.\n",
    "- <u>Densidad poblacional</u>: Calcularemos el mínimo, el máximo y la media de cada celda espacio-temporal.\n",
    "- <u>Distancia a carreteras</u>: Calcularemos la media, la mediana, el mínimo y el máximo.\n",
    "- <u>Distancia a rios</u>: Calcularemos la media, la mediana, el mínimo y el máximo.\n",
    "- <u>Distancia a vias de tren</u>: Calcularemos la media, la mediana, el mínimo y el máximo.\n",
    "- <u>Natura 2000</u>: Calcularemos la proporción de terreno de Natura 2000 que hay en cada celda.\n",
    "\n",
    "Es decir, de estos conjuntos de datos obtenemos 82 variables tabulares. Además, vamos a añadir las siguientes variables:\n",
    "- <u>Coordenada x</u> (número entero)\n",
    "- <u>Coordenada y</u> (número entero)\n",
    "- <u>Mes</u>: Mes en el que pasó el incendio\n",
    "\n",
    "Estas coordenadas sirven para identificar y ennumerar las celdas (son índices), es decir, la tupla (x,y) identifica a una única celda.\n",
    "\n",
    "<u>Nota</u>: La homogeneización de las variables y generación del \"datacube\" se ha hecho mediante el software QGIS: una herramienta que sirve para manejar datos espaciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Clase a predecir\n",
    "\n",
    "#### 3.2.1 Instancias positivas\n",
    "Una vez que tenemos bien definidas las instancias, la clase a predecir será si hay fuego en una celda un día concreto o no. Utilizando la última base de datos que no hemos usado, EFFIS, generamos las instancias positivas (en las que ha habido un incendio). Esto lo hemos hecho nuevamente utilizando el software QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['initialdate', 'finaldate', 'x_index', 'y_index', 'elevation_sum',\n",
       "       'elevation_mean', 'elevation_median', 'elevation_stdev',\n",
       "       'elevation_min', 'elevation_max', 'elevation_range', 'slope_sum',\n",
       "       'slope_mean', 'slope_median', 'slope_stdev', 'slope_min', 'slope_max',\n",
       "       'slope_range', 'aspect_NODATA', 'aspect_0_45', 'aspect_45_90',\n",
       "       'aspect_90_135', 'aspect_135_180', 'aspect_180_225', 'aspect_225_270',\n",
       "       'aspect_270_315', 'aspect_315_360', 'dist_to_road_mean',\n",
       "       'dist_to_road_median', 'dist_to_road_min', 'dist_to_road_max',\n",
       "       'dist_to_waterway_mean', 'dist_to_waterway_median',\n",
       "       'dist_to_waterway_min', 'dist_to_waterway_max', 'dist_to_railway_mean',\n",
       "       'dist_to_railway_median', 'dist_to_railway_min', 'dist_to_railway_max',\n",
       "       'natura2000_NODATA', 'natura2000_1', 'CLC_1', 'CLC_2', 'CLC_3', 'CLC_4',\n",
       "       'CLC_5', 'CLC_6', 'CLC_7', 'CLC_8', 'CLC_9', 'CLC_10', 'CLC_11',\n",
       "       'CLC_12', 'CLC_13', 'CLC_14', 'CLC_15', 'CLC_16', 'CLC_17', 'CLC_18',\n",
       "       'CLC_19', 'CLC_20', 'CLC_21', 'CLC_22', 'CLC_23', 'CLC_24', 'CLC_25',\n",
       "       'CLC_26', 'CLC_27', 'CLC_28', 'CLC_29', 'CLC_30', 'CLC_31', 'CLC_32',\n",
       "       'CLC_33', 'CLC_34', 'CLC_35', 'CLC_36', 'CLC_37', 'CLC_38', 'CLC_39',\n",
       "       'CLC_40', 'CLC_41', 'CLC_42', 'CLC_43', 'CLC_44', 'CLC_NODATA',\n",
       "       'population_density_mean', 'population_density_min',\n",
       "       'population_density_max', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fire_instances = pd.read_csv(\"../data/FinalDataset/Fire_instances_expandedbydate.csv\")\n",
    "# fire_instances.drop(columns=[\"initialdate\",\"finaldate\"], inplace=True)\n",
    "len(fire_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Instancias negativas\n",
    "\n",
    "El conjunto de datos real debería de tener todas las instancias negativas que ha habido, es decir, todas las celdas durante todos los días que no ha habido fuegos. Sin embargo, esto supondría tener alrededor de 100.000 instancias negativas por cada instancia positiva, por lo que para este trabajo tomaremos instancias negativas aleatoriamente hasta tener una cierta cantidad deseada.\n",
    "\n",
    "Entonces, para generar las instancias negativas tomaremos días aleatorios que no interfieran con las instancias positivas ya creadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x_index', 'y_index', 'elevation_sum', 'elevation_mean',\n",
       "       'elevation_median', 'elevation_stdev', 'elevation_min', 'elevation_max',\n",
       "       'elevation_range', 'slope_sum',\n",
       "       ...\n",
       "       'population_density_2020_mean', 'population_density_2020_min',\n",
       "       'population_density_2020_max', 'dist_to_railway_mean',\n",
       "       'dist_to_railway_median', 'dist_to_railway_min', 'dist_to_railway_max',\n",
       "       'natura2000_NODATA', 'natura2000_1', 'geometry'],\n",
       "      dtype='object', length=217)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacube = gpd.read_file(\"../data/FinalDataset/Datacube_1.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length = 0 / 157084\n",
      "Length = 1000 / 157084\n",
      "Length = 2000 / 157084\n",
      "Length = 3000 / 157084\n",
      "Length = 4000 / 157084\n",
      "Length = 5000 / 157084\n",
      "Length = 6000 / 157084\n",
      "Length = 7000 / 157084\n",
      "Length = 8000 / 157084\n",
      "Length = 9000 / 157084\n",
      "Length = 10000 / 157084\n",
      "Length = 11000 / 157084\n",
      "Length = 12000 / 157084\n",
      "Length = 13000 / 157084\n",
      "Length = 14000 / 157084\n",
      "Length = 15000 / 157084\n",
      "Length = 16000 / 157084\n",
      "Length = 17000 / 157084\n",
      "Length = 18000 / 157084\n",
      "Length = 19000 / 157084\n",
      "Length = 20000 / 157084\n",
      "Length = 21000 / 157084\n",
      "Length = 22000 / 157084\n",
      "Length = 23000 / 157084\n",
      "Length = 24000 / 157084\n",
      "Length = 25000 / 157084\n",
      "Length = 26000 / 157084\n",
      "Length = 27000 / 157084\n",
      "Length = 28000 / 157084\n",
      "Length = 29000 / 157084\n",
      "Length = 30000 / 157084\n",
      "Length = 31000 / 157084\n",
      "Length = 32000 / 157084\n",
      "Length = 33000 / 157084\n",
      "Length = 34000 / 157084\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'finaldate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1159\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_with_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   1161\u001b[0m     \u001b[38;5;66;03m# We have a scalar (or for MultiIndex or object-dtype, scalar-like)\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;66;03m#  key that is not present in self.index.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1222\u001b[0m, in \u001b[0;36mSeries._set_with_engine\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_with_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1222\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1224\u001b[0m     \u001b[38;5;66;03m# this is equivalent to self._values[key] = value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'finaldate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m random_date \u001b[38;5;241m=\u001b[39m generate_random_date(start_date\u001b[38;5;241m=\u001b[39mdatetime(\u001b[38;5;241m2008\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     65\u001b[0m                                    end_date\u001b[38;5;241m=\u001b[39mdatetime(\u001b[38;5;241m2024\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m31\u001b[39m))\n\u001b[0;32m     66\u001b[0m random_box[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitialdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m random_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m \u001b[43mrandom_box\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinaldate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m random_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m nofire_instances[i] \u001b[38;5;241m=\u001b[39m GenerateBox(random_date, random_box)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1174\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1171\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_values(key, value)\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;66;03m# GH#12862 adding a new key to the Series\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;66;03m# The key was OK, but we cannot set the value losslessly\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(key)\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 849\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1825\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1822\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1825\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1829\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:2090\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2089\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m-> 2090\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m     \u001b[38;5;66;03m# we have a coerced indexer, e.g. a float\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m     \u001b[38;5;66;03m# that matches in an int64 Index, so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m     \u001b[38;5;66;03m# we will not create a duplicate index, rather\u001b[39;00m\n\u001b[0;32m   2095\u001b[0m     \u001b[38;5;66;03m# index to that element\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m     \u001b[38;5;66;03m# e.g. 0.0 -> 0\u001b[39;00m\n\u001b[0;32m   2097\u001b[0m     \u001b[38;5;66;03m# GH#12246\u001b[39;00m\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   2099\u001b[0m         \u001b[38;5;66;03m# pass new_index[-1:] instead if [new_index[-1]]\u001b[39;00m\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;66;03m#  so that we retain dtype\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6652\u001b[0m, in \u001b[0;36mIndex.insert\u001b[1;34m(self, loc, item)\u001b[0m\n\u001b[0;32m   6645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   6646\u001b[0m     item, (\u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64)\n\u001b[0;32m   6647\u001b[0m ):\n\u001b[0;32m   6648\u001b[0m     \u001b[38;5;66;03m# with object-dtype we need to worry about numpy incorrectly casting\u001b[39;00m\n\u001b[0;32m   6649\u001b[0m     \u001b[38;5;66;03m# dt64/td64 to integer, also about treating tuples as sequences\u001b[39;00m\n\u001b[0;32m   6650\u001b[0m     \u001b[38;5;66;03m# special-casing dt64/td64 https://github.com/numpy/numpy/issues/12550\u001b[39;00m\n\u001b[0;32m   6651\u001b[0m     casted \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(item)\n\u001b[1;32m-> 6652\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6655\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"insert\" matches argument types\u001b[39;00m\n\u001b[0;32m   6656\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"int\", \"None\"\u001b[39;00m\n\u001b[0;32m   6657\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(arr, loc, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minsert\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\julen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:5402\u001b[0m, in \u001b[0;36minsert\u001b[1;34m(arr, obj, values, axis)\u001b[0m\n\u001b[0;32m   5400\u001b[0m numnew \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m   5401\u001b[0m newshape[axis] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numnew\n\u001b[1;32m-> 5402\u001b[0m new \u001b[38;5;241m=\u001b[39m empty(newshape, arr\u001b[38;5;241m.\u001b[39mdtype, arrorder)\n\u001b[0;32m   5403\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, index)\n\u001b[0;32m   5404\u001b[0m new[\u001b[38;5;28mtuple\u001b[39m(slobj)] \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;28mtuple\u001b[39m(slobj)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def GenerateBox(date, row):\n",
    "    \"\"\"\n",
    "    Receives as inputs a date and a row from the datacube, \n",
    "    \n",
    "    and returns the values of the row filtered by the selected date.\n",
    "    \"\"\"\n",
    "\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "\n",
    "    selected_columns = [\"initialdate\", \"finaldate\", \"x_index\", \"y_index\",\n",
    "                        \"elevation_sum\", \"elevation_mean\", \"elevation_median\",\"elevation_stdev\", \"elevation_min\", \"elevation_max\", \"elevation_range\",\n",
    "                        \"slope_sum\", \"slope_mean\", \"slope_median\", \"slope_stdev\", \"slope_min\", \"slope_max\", \"slope_range\",\n",
    "                        \"aspect_NODATA\", \"aspect_0_45\", \"aspect_45_90\", \"aspect_90_135\", \"aspect_135_180\", \"aspect_180_225\", \"aspect_225_270\", \"aspect_270_315\", \"aspect_315_360\",\n",
    "                        \"dist_to_road_mean\", \"dist_to_road_median\", \"dist_to_road_min\", \"dist_to_road_max\",\n",
    "                        \"dist_to_waterway_mean\", \"dist_to_waterway_median\", \"dist_to_waterway_min\", \"dist_to_waterway_max\",\n",
    "                        \"dist_to_railway_mean\", \"dist_to_railway_median\", \"dist_to_railway_min\", \"dist_to_railway_max\",\n",
    "                        \"natura2000_NODATA\", \"natura2000_1\"\n",
    "                        ]  \n",
    "    \n",
    "    # Corine Land Cover\n",
    "    if year < 2012:\n",
    "        year_clc = 2006\n",
    "    elif year < 2018:\n",
    "        year_clc = 2012\n",
    "    else:\n",
    "        year_clc = 2018\n",
    "    clc_columns = [f\"CLC_{year_clc}_{i}\" for i in range(1,45)]\n",
    "    selected_columns = selected_columns + clc_columns + [f\"CLC_{year_clc}_NODATA\"]\n",
    "\n",
    "    # Population Density\n",
    "    if year > 2020:\n",
    "        year_popdens = 2020\n",
    "    else:\n",
    "        year_popdens = year\n",
    "    popdens_columns = [f\"population_density_{year_popdens}_{case}\" for case in [\"mean\", \"min\", \"max\"]]\n",
    "    selected_columns += popdens_columns\n",
    "    \n",
    "    filtered_row_values = row[selected_columns].values\n",
    "    filtered_row_values = np.append(filtered_row_values, [int(month)])\n",
    "\n",
    "    return filtered_row_values\n",
    "\n",
    "\n",
    "def generate_random_date(start_date, end_date):\n",
    "    delta = end_date - start_date\n",
    "    random_days = random.randint(0, delta.days)\n",
    "    return start_date + timedelta(days=random_days)\n",
    "\n",
    "def check_box(box, fire_instances):\n",
    "    \"\"\"\n",
    "    Receives as inputs a box and returns whether the box has collisions with fire instances.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "n_nofire_instances = 2 * len(fire_instances)\n",
    "nofire_instances = np.zeros((n_nofire_instances, len(fire_instances.columns)), dtype=object)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "i = 0\n",
    "while i < len(nofire_instances):\n",
    "    i_random = random.randint(0,len(datacube)-1) # Select random box\n",
    "    random_box = datacube.iloc[i_random]\n",
    "    random_date = generate_random_date(start_date=datetime(2008,1,1),\n",
    "                                       end_date=datetime(2024,12,31))\n",
    "    random_box[\"initialdate\"] = random_date.strftime('%Y-%m-%d')\n",
    "    random_box[\"finaldate\"] = random_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    random_box_values = GenerateBox(random_date, random_box)\n",
    "    if check_box(random_box_values, fire_instances):\n",
    "        nofire_instances[i] = random_box_values\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Length = {i} / {n_nofire_instances}\")\n",
    "\n",
    "warnings.simplefilter(action='default', category=pd.errors.SettingWithCopyWarning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
